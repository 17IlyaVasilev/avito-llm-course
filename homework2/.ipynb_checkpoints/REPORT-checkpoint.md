# Homework 2

## 1) Сетап
- GPU: 2× A100 80GB (но они обе загружены более чем на половину, другими процессами)
- NVIDIA-SMI 545.23.08, Driver Version: 545.23.08, CUDA Version: 12.3
- Запуск обучения на олной карте, на двух картах (просто, с ипользованием ds, с использованием fsdp)

## 2) Запуск экспериментов
- Обучение на одной карте: accelerate launch --num_processes 1 your_solution.py
- Обучение на двух картах: accelerate launch --num_processes 2 your_solution.py
  Нужно положить в переменную в скрипте нужное значение стратегрии:
      использование обычного режима: TRAIN_STRATEGY = 'base';
      использование ds режима: TRAIN_STRATEGY = 'ds';
      использование fsdp режима: TRAIN_STRATEGY = 'fsdp'

## 3) Метрики
            | eval_loss |  samples  | memory 1 GPU |
1 GPU       |   4.88    |   28832   |     27.7G    |
2 GPU       |   3.92    |   47616   |     28.2G    |
2 GPU DS    |   4.26    |   32128   |      34G     |
2 GPU FSDP  |   4.34    |   27744   |      30G     |


## 4) Выводы
К сожалению, методы оптимизации параллельного обучения на 2 GPU не показали ожидаемого результата (ну или я что-то делал не так).
Однако они показали лучше eval_loss, чем те же параметры при обучении с однйо GPU. 
При этом параллельное обучение без использования ds и fsdp заметно лучше себя показывает, как с точки зрения скорости обучения и качества, так и памяти.
Возможно такие результаты получились из-за небольшо батча (все-таки на картах крутились и другие процессы, от которых я не мог избавиться).
Также сама модель не особо большая по параметрам и обучение длится всего лишь 30 минут, так что мб из-за этого не получилось показать всю силу этих методов.
Также мной было замечено, что обучение на 2 GPU без использования ds и fsdp в 3 раза быстрее прогоняло eval, что дало преимущество по времени.