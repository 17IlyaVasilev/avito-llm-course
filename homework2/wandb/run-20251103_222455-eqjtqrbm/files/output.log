Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 109744.67it/s]
Loading dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:00<00:00, 10115.76it/s]
Training samples: 1940063
Validation samples: 5000
Model pad token id: 0
Total params: 960,881,664
[2025-11-03 22:25:45,923] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-11-03 22:25:47,019] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-11-03 22:25:47,020] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/workspace/llm/avito-llm-course/homework2/your_solution.py:410: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Using /root/.cache/torch_extensions/py312_cu126 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /root/.cache/torch_extensions/py312_cu126/fused_adam/build.ninja...
/usr/local/lib/python3.12/dist-packages/torch/utils/cpp_extension.py:2007: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Time to load fused_adam op: 0.05085468292236328 seconds
[2025-11-03 22:26:02,652] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                        | 0/30314 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
[rank0]:W1103 22:26:03.858000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [3/0] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:26:03.860000 20371 torch/fx/experimental/recording.py:298] [3/0] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 22:26:07.558000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [4/0] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:26:07.559000 20371 torch/fx/experimental/recording.py:298] [4/0] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
  0%|â–                                                                                                                                          | 100/30314 [02:40<11:35:27,  1.38s/it][rank0]:W1103 22:28:44.245000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [1/1] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
{'loss': 8.1528, 'grad_norm': 0.9038010239601135, 'learning_rate': 0.0006084231855465311, 'epoch': 0.0}
[rank0]:E1103 22:28:44.248000 20371 torch/fx/experimental/recording.py:298] [1/1] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 22:28:44.289000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [2/1] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:28:44.290000 20371 torch/fx/experimental/recording.py:298] [2/1] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 22:28:44.436000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [4/1] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:28:44.437000 20371 torch/fx/experimental/recording.py:298] [4/1] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 22:28:45.176000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [18/0] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:28:45.177000 20371 torch/fx/experimental/recording.py:298] [18/0] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 22:28:52.444000 20371 torch/_dynamo/convert_frame.py:861] [21/8] torch._dynamo hit config.cache_size_limit (8)
[rank0]:W1103 22:28:52.444000 20371 torch/_dynamo/convert_frame.py:861] [21/8]    function: 'forward' (/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py:201)
[rank0]:W1103 22:28:52.444000 20371 torch/_dynamo/convert_frame.py:861] [21/8]    last reason: 21/0: L['self'].layer_idx == 0
[rank0]:W1103 22:28:52.444000 20371 torch/_dynamo/convert_frame.py:861] [21/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
[rank0]:W1103 22:28:52.444000 20371 torch/_dynamo/convert_frame.py:861] [21/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
  3%|â–ˆâ–ˆâ–ˆâ–                                                                                                                                       | 762/30314 [30:09<19:29:28,  2.37s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:15<00:00, 20.79it/s]
{'eval_loss': 7.023568630218506, 'eval_runtime': 33.3575, 'eval_samples_per_second': 149.891, 'eval_steps_per_second': 9.383, 'epoch': 0.0}
{'loss': 5.9151, 'grad_norm': 0.5516400337219238, 'learning_rate': 0.0007, 'epoch': 0.01}
{'eval_loss': 5.975593566894531, 'eval_runtime': 15.4963, 'eval_samples_per_second': 322.658, 'eval_steps_per_second': 20.198, 'epoch': 0.01}
{'loss': 5.1207, 'grad_norm': 0.46929264068603516, 'learning_rate': 0.0007, 'epoch': 0.01}
{'eval_loss': 5.438072204589844, 'eval_runtime': 15.9209, 'eval_samples_per_second': 314.052, 'eval_steps_per_second': 19.66, 'epoch': 0.01}
{'loss': 4.6954, 'grad_norm': 0.3877961039543152, 'learning_rate': 0.0007, 'epoch': 0.01}
{'eval_loss': 5.136651515960693, 'eval_runtime': 15.5303, 'eval_samples_per_second': 321.952, 'eval_steps_per_second': 20.154, 'epoch': 0.01}
{'loss': 4.4057, 'grad_norm': 0.3929899036884308, 'learning_rate': 0.0007, 'epoch': 0.02}
{'eval_loss': 4.9363322257995605, 'eval_runtime': 15.4529, 'eval_samples_per_second': 323.564, 'eval_steps_per_second': 20.255, 'epoch': 0.02}
{'loss': 4.2075, 'grad_norm': 0.4124244451522827, 'learning_rate': 0.0007, 'epoch': 0.02}
{'eval_loss': 4.768492221832275, 'eval_runtime': 15.4434, 'eval_samples_per_second': 323.764, 'eval_steps_per_second': 20.268, 'epoch': 0.02}
{'loss': 4.0362, 'grad_norm': 0.3344608247280121, 'learning_rate': 0.0007, 'epoch': 0.02}
{'eval_loss': 4.585632801055908, 'eval_runtime': 15.6784, 'eval_samples_per_second': 318.91, 'eval_steps_per_second': 19.964, 'epoch': 0.02}
Training stopped after 1801.12s (timeout)
{'train_runtime': 1809.3128, 'train_samples_per_second': 1072.265, 'train_steps_per_second': 16.754, 'train_loss': 5.110871642906209, 'epoch': 0.03}
Running final evaluation...
Final evaluation results: {'eval_loss': 4.585632801055908, 'eval_runtime': 15.4172, 'eval_samples_per_second': 324.313, 'eval_steps_per_second': 20.302, 'epoch': 0.02513731505764758}
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
[rank0]:W1103 22:56:28.296000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [1/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:56:28.298000 20371 torch/fx/experimental/recording.py:298] [1/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 22:56:28.345000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [2/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:56:28.347000 20371 torch/fx/experimental/recording.py:298] [2/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 22:56:28.900000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [4/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:56:28.901000 20371 torch/fx/experimental/recording.py:298] [4/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 22:56:29.009000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [18/1] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:56:29.010000 20371 torch/fx/experimental/recording.py:298] [18/1] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 22:56:34.027000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [1/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:56:34.029000 20371 torch/fx/experimental/recording.py:298] [1/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 22:56:34.073000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [2/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:56:34.074000 20371 torch/fx/experimental/recording.py:298] [2/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 22:56:34.698000 20371 torch/fx/experimental/symbolic_shapes.py:5858] [4/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 22:56:34.699000 20371 torch/fx/experimental/recording.py:298] [4/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})

----------------------------------------------------------------------------------------------------
Ð’ Ð´Ñ€ÐµÐ²Ð½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð°, ÐºÐ¾Ð³Ð´Ð° Ð»ÑŽÐ´Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð°Ñ‡Ð¸Ð½Ð°Ð»Ð¸ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ, Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ð»Ð¸...

Ð’Ñ‚Ð¾Ñ€Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ Ñ‚ÐµÑ€Ñ€Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¸ Ð³Ð¾Ñ€Ð¾Ð´Ð°, Ð² Ñ‚Ð¾Ð¼ Ñ‡Ð¸ÑÐ»Ðµ, Ñ‡Ñ‚Ð¾ Ð² ÐºÐ¾Ð½Ñ†Ðµ XIX Ð²ÐµÐºÐ°, ÐºÐ¾Ð³Ð´Ð° Ð² Ñ…Ð¾Ð´Ðµ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¸Ñ, Ð² Ñ…Ð¾Ð´Ðµ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¸Ñ, Ð² Ñ…Ð¾Ð´Ðµ Ð’Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð¼Ð¸Ñ€Ð¾Ð²Ð¾Ð¹ Ð²Ð¾Ð¹Ð½Ñ‹, Ð² Ñ…Ð¾Ð´Ðµ Ð’Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð¼Ð¸Ñ€Ð¾Ð²Ð¾Ð¹ Ð²Ð¾Ð¹Ð½Ñ‹, Ð² Ñ…Ð¾Ð´Ðµ Ð’Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð¼Ð¸Ñ€Ð¾Ð²Ð¾Ð¹ Ð²Ð¾Ð¹Ð½Ñ‹, Ð² Ñ…Ð¾Ð´Ðµ Ð’Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð¼Ð¸Ñ€Ð¾Ð²Ð¾Ð¹ Ð²Ð¾Ð¹Ð½Ñ‹, Ð² Ñ…Ð¾Ð´Ðµ Ð’Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð¼Ð¸Ñ€Ð¾Ð²Ð¾Ð¹ Ð²Ð¾Ð¹Ð½Ñ‹, Ð² Ñ…Ð¾Ð´Ðµ Ð’Ñ‚Ð¾Ñ€Ð¾Ð¹
----------------------------------------------------------------------------------------------------
