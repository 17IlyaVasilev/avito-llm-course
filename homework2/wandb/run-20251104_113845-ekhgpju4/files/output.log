Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 109386.90it/s]
Loading dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:00<00:00, 9064.93it/s]
Training samples: 1940063
Validation samples: 5000
Model pad token id: 0
Total params: 960,881,664
[2025-11-04 11:39:36,200] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-11-04 11:39:37,240] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-11-04 11:39:37,241] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/workspace/llm/avito-llm-course/homework2/your_solution.py:408: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Using /root/.cache/torch_extensions/py312_cu126 as PyTorch extensions root...
Loading extension module fused_adam...
Time to load fused_adam op: 0.1032721996307373 seconds
[2025-11-04 11:39:53,434] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                        | 0/60627 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
[rank0]:W1104 11:39:54.632000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [3/0] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 11:39:54.634000 29704 torch/fx/experimental/recording.py:298] [3/0] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
[rank0]:W1104 11:39:57.221000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [4/0] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 11:39:57.222000 29704 torch/fx/experimental/recording.py:298] [4/0] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
  0%|â–                                                                                                                                          | 100/60627 [02:15<18:57:03,  1.13s/it][rank0]:W1104 11:42:10.185000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [1/1] failed during evaluate_expr(Ne(u0, s0), hint=None, size_oblivious=False, forcing_spec=False
{'loss': 7.9558, 'grad_norm': 1.327695369720459, 'learning_rate': 0.000347670391740875, 'epoch': 0.0}
[rank0]:E1104 11:42:10.188000 29704 torch/fx/experimental/recording.py:298] [1/1] failed while running evaluate_expr(*(Ne(u0, s0), None), **{'fx_node': False})
[rank0]:W1104 11:42:10.239000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [2/1] failed during evaluate_expr(Ne(u0, s0), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 11:42:10.241000 29704 torch/fx/experimental/recording.py:298] [2/1] failed while running evaluate_expr(*(Ne(u0, s0), None), **{'fx_node': False})
[rank0]:W1104 11:42:11.422000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [4/1] failed during evaluate_expr(Ne(u0, s1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 11:42:11.425000 29704 torch/fx/experimental/recording.py:298] [4/1] failed while running evaluate_expr(*(Ne(u0, s1), None), **{'fx_node': False})
[rank0]:W1104 11:42:12.263000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [18/0] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 11:42:12.264000 29704 torch/fx/experimental/recording.py:298] [18/0] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
[rank0]:W1104 11:42:27.645000 29704 torch/_dynamo/convert_frame.py:861] [21/8] torch._dynamo hit config.cache_size_limit (8)
[rank0]:W1104 11:42:27.645000 29704 torch/_dynamo/convert_frame.py:861] [21/8]    function: 'forward' (/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py:201)
[rank0]:W1104 11:42:27.645000 29704 torch/_dynamo/convert_frame.py:861] [21/8]    last reason: 21/0: L['self'].layer_idx == 0
[rank0]:W1104 11:42:27.645000 29704 torch/_dynamo/convert_frame.py:861] [21/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
[rank0]:W1104 11:42:27.645000 29704 torch/_dynamo/convert_frame.py:861] [21/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
  1%|â–ˆâ–‰                                                                                                                                         | 851/60627 [30:09<35:17:59,  2.13s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:15<00:00, 20.63it/s]
{'eval_loss': 7.161006450653076, 'eval_runtime': 48.2563, 'eval_samples_per_second': 103.613, 'eval_steps_per_second': 6.486, 'epoch': 0.0}
{'loss': 6.2344, 'grad_norm': 0.8096268773078918, 'learning_rate': 0.0004, 'epoch': 0.0}
{'eval_loss': 6.345606803894043, 'eval_runtime': 15.245, 'eval_samples_per_second': 327.977, 'eval_steps_per_second': 20.531, 'epoch': 0.0}
{'loss': 5.4447, 'grad_norm': 0.7230226993560791, 'learning_rate': 0.0004, 'epoch': 0.0}
{'eval_loss': 5.863897800445557, 'eval_runtime': 15.2398, 'eval_samples_per_second': 328.089, 'eval_steps_per_second': 20.538, 'epoch': 0.0}
{'loss': 5.1056, 'grad_norm': 0.6917375922203064, 'learning_rate': 0.0004, 'epoch': 0.01}
{'eval_loss': 5.57373571395874, 'eval_runtime': 15.2965, 'eval_samples_per_second': 326.873, 'eval_steps_per_second': 20.462, 'epoch': 0.01}
{'loss': 4.8568, 'grad_norm': 0.6564834117889404, 'learning_rate': 0.0004, 'epoch': 0.01}
{'eval_loss': 5.351473808288574, 'eval_runtime': 15.6516, 'eval_samples_per_second': 319.457, 'eval_steps_per_second': 19.998, 'epoch': 0.01}
{'loss': 4.6727, 'grad_norm': 0.5530295372009277, 'learning_rate': 0.0004, 'epoch': 0.01}
{'eval_loss': 5.207563877105713, 'eval_runtime': 15.3652, 'eval_samples_per_second': 325.41, 'eval_steps_per_second': 20.371, 'epoch': 0.01}
{'loss': 4.5271, 'grad_norm': 0.6413136720657349, 'learning_rate': 0.0004, 'epoch': 0.01}
{'eval_loss': 5.0777692794799805, 'eval_runtime': 15.5781, 'eval_samples_per_second': 320.964, 'eval_steps_per_second': 20.092, 'epoch': 0.01}
{'loss': 4.3828, 'grad_norm': 0.5803307294845581, 'learning_rate': 0.0004, 'epoch': 0.01}
{'eval_loss': 4.940752029418945, 'eval_runtime': 15.6506, 'eval_samples_per_second': 319.476, 'eval_steps_per_second': 19.999, 'epoch': 0.01}
Training stopped after 1801.06s (timeout)
{'train_runtime': 1809.1685, 'train_samples_per_second': 1072.351, 'train_steps_per_second': 33.511, 'train_loss': 5.331203223115269, 'epoch': 0.01}
Running final evaluation...
Final evaluation results: {'eval_loss': 4.940752029418945, 'eval_runtime': 15.5111, 'eval_samples_per_second': 322.35, 'eval_steps_per_second': 20.179, 'epoch': 0.01403665033730846}
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
[rank0]:W1104 12:10:18.973000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [1/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 12:10:18.975000 29704 torch/fx/experimental/recording.py:298] [1/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1104 12:10:19.026000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [2/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 12:10:19.027000 29704 torch/fx/experimental/recording.py:298] [2/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1104 12:10:20.492000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [4/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 12:10:20.493000 29704 torch/fx/experimental/recording.py:298] [4/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1104 12:10:20.740000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [18/1] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 12:10:20.741000 29704 torch/fx/experimental/recording.py:298] [18/1] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
[rank0]:W1104 12:10:25.547000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [1/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 12:10:25.550000 29704 torch/fx/experimental/recording.py:298] [1/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1104 12:10:25.600000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [2/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 12:10:25.601000 29704 torch/fx/experimental/recording.py:298] [2/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1104 12:10:26.604000 29704 torch/fx/experimental/symbolic_shapes.py:5858] [4/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1104 12:10:26.605000 29704 torch/fx/experimental/recording.py:298] [4/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})

----------------------------------------------------------------------------------------------------
Ð’ Ð´Ñ€ÐµÐ²Ð½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð°, ÐºÐ¾Ð³Ð´Ð° Ð»ÑŽÐ´Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð°Ñ‡Ð¸Ð½Ð°Ð»Ð¸ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ, Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ð»Ð¸..., Ð¸ Ð² Ñ‚Ð¾ Ð²Ñ€ÐµÐ¼Ñ ÐºÐ°Ðº Ð² Ð Ð¾ÑÑÐ¸Ð¸, ÐºÐ¾Ð³Ð´Ð° Ð¾Ð½Ð° Ð±Ñ‹Ð»Ð° Ð¾Ð´Ð½Ð¾Ð¹ Ð¸Ð· ÑÐ°Ð¼Ñ‹Ñ… Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ñ… ÑÑ‚Ñ€Ð°Ð½.

Ð’ Ð Ð¾ÑÑÐ¸Ð¸
Ð’ Ð Ð¾ÑÑÐ¸Ð¸ Ð² Ð¡Ð¨Ð, Ð² Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð, Ð¡Ð¨Ð,
----------------------------------------------------------------------------------------------------
