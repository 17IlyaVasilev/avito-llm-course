Resolving data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 99126.83it/s]
Loading dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46/46 [00:00<00:00, 9553.28it/s]
Training samples: 1940063
Validation samples: 5000
Model pad token id: 0
Total params: 960,881,664
[2025-11-03 16:25:13,793] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-11-03 16:25:14,853] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-11-03 16:25:14,854] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
/workspace/llm/avito-llm-course/homework2/your_solution.py:414: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Using /root/.cache/torch_extensions/py312_cu126 as PyTorch extensions root...
Loading extension module fused_adam...
Time to load fused_adam op: 27.737942695617676 seconds
[2025-11-03 16:25:59,455] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[34m[1mwandb[0m: [33mWARNING[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                        | 0/30314 [00:00<?, ?it/s][rank0]:W1103 16:26:00.961000 544 torch/fx/experimental/symbolic_shapes.py:5858] [0/0] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:26:00.964000 544 torch/fx/experimental/recording.py:298] [0/0] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 16:26:01.002000 544 torch/fx/experimental/symbolic_shapes.py:5858] [1/0] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:26:01.004000 544 torch/fx/experimental/recording.py:298] [1/0] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 16:26:01.053000 544 torch/fx/experimental/symbolic_shapes.py:5858] [2/0] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:26:01.054000 544 torch/fx/experimental/recording.py:298] [2/0] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 16:26:08.194000 544 torch/fx/experimental/symbolic_shapes.py:5858] [3/0] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:26:08.195000 544 torch/fx/experimental/recording.py:298] [3/0] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 16:26:08.916000 544 torch/fx/experimental/symbolic_shapes.py:5858] [4/0] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:26:08.917000 544 torch/fx/experimental/recording.py:298] [4/0] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 16:26:34.356000 544 torch/_dynamo/convert_frame.py:861] [10/8] torch._dynamo hit config.cache_size_limit (8)
[rank0]:W1103 16:26:34.356000 544 torch/_dynamo/convert_frame.py:861] [10/8]    function: 'forward' (/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py:201)
[rank0]:W1103 16:26:34.356000 544 torch/_dynamo/convert_frame.py:861] [10/8]    last reason: 10/0: L['self'].layer_idx == 0
[rank0]:W1103 16:26:34.356000 544 torch/_dynamo/convert_frame.py:861] [10/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
[rank0]:W1103 16:26:34.356000 544 torch/_dynamo/convert_frame.py:861] [10/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
  0%|â–                                                                                                                                          | 100/30314 [03:11<11:09:03,  1.33s/it][rank0]:W1103 16:29:11.280000 544 torch/fx/experimental/symbolic_shapes.py:5858] [1/1] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
{'loss': 7.7995, 'grad_norm': 0.9410390853881836, 'learning_rate': 0.000347670391740875, 'epoch': 0.0}
[rank0]:E1103 16:29:11.282000 544 torch/fx/experimental/recording.py:298] [1/1] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 16:29:11.324000 544 torch/fx/experimental/symbolic_shapes.py:5858] [2/1] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:29:11.325000 544 torch/fx/experimental/recording.py:298] [2/1] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 16:29:11.470000 544 torch/fx/experimental/symbolic_shapes.py:5858] [3/1] failed during evaluate_expr(Ne(u0, 8), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:29:11.471000 544 torch/fx/experimental/recording.py:298] [3/1] failed while running evaluate_expr(*(Ne(u0, 8), None), **{'fx_node': False})
[rank0]:W1103 16:29:11.520000 544 torch/fx/experimental/symbolic_shapes.py:5858] [4/1] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:29:11.521000 544 torch/fx/experimental/recording.py:298] [4/1] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                                     | 1071/30314 [30:09<13:43:15,  1.69s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:16<00:00, 18.62it/s]
{'eval_loss': 6.812567234039307, 'eval_runtime': 21.6864, 'eval_samples_per_second': 230.56, 'eval_steps_per_second': 14.433, 'epoch': 0.0}
{'loss': 5.724, 'grad_norm': 0.6422125697135925, 'learning_rate': 0.0004, 'epoch': 0.01}
{'eval_loss': 5.8669867515563965, 'eval_runtime': 17.2832, 'eval_samples_per_second': 289.298, 'eval_steps_per_second': 18.11, 'epoch': 0.01}
{'loss': 5.0228, 'grad_norm': 0.5521194934844971, 'learning_rate': 0.0004, 'epoch': 0.01}
{'eval_loss': 5.388119697570801, 'eval_runtime': 17.2608, 'eval_samples_per_second': 289.673, 'eval_steps_per_second': 18.134, 'epoch': 0.01}
{'loss': 4.6309, 'grad_norm': 0.47809329628944397, 'learning_rate': 0.0004, 'epoch': 0.01}
{'eval_loss': 5.098268985748291, 'eval_runtime': 17.1138, 'eval_samples_per_second': 292.161, 'eval_steps_per_second': 18.289, 'epoch': 0.01}
{'loss': 4.3607, 'grad_norm': 0.4890030026435852, 'learning_rate': 0.0004, 'epoch': 0.02}
{'eval_loss': 4.9078569412231445, 'eval_runtime': 17.0806, 'eval_samples_per_second': 292.73, 'eval_steps_per_second': 18.325, 'epoch': 0.02}
{'loss': 4.1791, 'grad_norm': 0.5215116143226624, 'learning_rate': 0.0004, 'epoch': 0.02}
{'eval_loss': 4.75496768951416, 'eval_runtime': 17.3356, 'eval_samples_per_second': 288.424, 'eval_steps_per_second': 18.055, 'epoch': 0.02}
{'loss': 4.0338, 'grad_norm': 0.428802490234375, 'learning_rate': 0.0004, 'epoch': 0.02}
{'eval_loss': 4.593210220336914, 'eval_runtime': 17.4174, 'eval_samples_per_second': 287.069, 'eval_steps_per_second': 17.971, 'epoch': 0.02}
{'loss': 3.9001, 'grad_norm': 0.4373829662799835, 'learning_rate': 0.0004, 'epoch': 0.03}
{'eval_loss': 4.485941410064697, 'eval_runtime': 17.6065, 'eval_samples_per_second': 283.986, 'eval_steps_per_second': 17.778, 'epoch': 0.03}
{'loss': 3.7649, 'grad_norm': 0.4247618019580841, 'learning_rate': 0.0004, 'epoch': 0.03}
{'eval_loss': 4.359235763549805, 'eval_runtime': 17.556, 'eval_samples_per_second': 284.803, 'eval_steps_per_second': 17.829, 'epoch': 0.03}
{'loss': 3.6467, 'grad_norm': 0.3995862305164337, 'learning_rate': 0.0004, 'epoch': 0.03}
{'eval_loss': 4.260244369506836, 'eval_runtime': 17.3415, 'eval_samples_per_second': 288.326, 'eval_steps_per_second': 18.049, 'epoch': 0.03}
Training stopped after 1800.01s (timeout)
{'train_runtime': 1809.0754, 'train_samples_per_second': 1072.406, 'train_steps_per_second': 16.757, 'train_loss': 4.626633003868865, 'epoch': 0.04}
Running final evaluation...
Final evaluation results: {'eval_loss': 4.260244369506836, 'eval_runtime': 17.2891, 'eval_samples_per_second': 289.2, 'eval_steps_per_second': 18.104, 'epoch': 0.03533079321094562}
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
[rank0]:W1103 16:56:26.800000 544 torch/fx/experimental/symbolic_shapes.py:5858] [1/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:56:26.802000 544 torch/fx/experimental/recording.py:298] [1/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 16:56:26.854000 544 torch/fx/experimental/symbolic_shapes.py:5858] [2/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:56:26.855000 544 torch/fx/experimental/recording.py:298] [2/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 16:56:27.905000 544 torch/fx/experimental/symbolic_shapes.py:5858] [3/2] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:56:27.906000 544 torch/fx/experimental/recording.py:298] [3/2] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 16:56:28.768000 544 torch/fx/experimental/symbolic_shapes.py:5858] [4/2] failed during evaluate_expr(Eq(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:56:28.769000 544 torch/fx/experimental/recording.py:298] [4/2] failed while running evaluate_expr(*(Eq(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 16:56:36.197000 544 torch/fx/experimental/symbolic_shapes.py:5858] [1/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:56:36.199000 544 torch/fx/experimental/recording.py:298] [1/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 16:56:36.242000 544 torch/fx/experimental/symbolic_shapes.py:5858] [2/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:56:36.245000 544 torch/fx/experimental/recording.py:298] [2/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})
[rank0]:W1103 16:56:36.907000 544 torch/fx/experimental/symbolic_shapes.py:5858] [3/3] failed during evaluate_expr(Ne(u0, 1), hint=None, size_oblivious=False, forcing_spec=False
[rank0]:E1103 16:56:36.908000 544 torch/fx/experimental/recording.py:298] [3/3] failed while running evaluate_expr(*(Ne(u0, 1), None), **{'fx_node': False})

----------------------------------------------------------------------------------------------------
Ð’ Ð´Ñ€ÐµÐ²Ð½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð°, ÐºÐ¾Ð³Ð´Ð° Ð»ÑŽÐ´Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð°Ñ‡Ð¸Ð½Ð°Ð»Ð¸ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ, Ð½Ð¾ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ Ñ‡ÐµÐ³Ð¾ Ð¾Ð½Ð¸ Ð±Ñ‹Ð»Ð¸ Ñ‚Ñ‰ÐµÑ‚Ð½Ñ‹Ð¼Ð¸.

Ð’ 1775 Ð³Ð¾Ð´Ñƒ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¸Ñ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð² 1796 Ð³Ð¾Ð´Ñƒ, Ð²
----------------------------------------------------------------------------------------------------
